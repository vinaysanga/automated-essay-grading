{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Importing the Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Constants\n",
    "DATASET_DIR = './data/'\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "X = pd.read_csv(os.path.join(DATASET_DIR, 'training_set_rel3.tsv'), sep='\\t', encoding='ISO-8859-1')\n",
    "y = X['domain1_score']\n",
    "X = X.dropna(axis=1)\n",
    "X = X.drop(columns=['rater1_domain1', 'rater2_domain1'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "X.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   domain1_score  \n",
       "0              8  \n",
       "1              9  \n",
       "2              7  \n",
       "3             10  \n",
       "4              8  "
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Minimum and Maximum Scores for each essay set."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "minimum_scores = [-1, 2, 1, 0, 0, 0, 0, 0, 0]\n",
    "maximum_scores = [-1, 12, 6, 3, 3, 4, 4, 30, 60]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing the Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will preprocess all essays and convert them to feature vectors so that they can be fed into the BiLSTM.\n",
    "\n",
    "These are all helper functions used to clean the essays."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "def essay_to_wordlist(essay_v, remove_stopwords):\n",
    "    \"\"\"Remove the tagged labels and word tokenize the sentence.\"\"\"\n",
    "    essay_v = re.sub(\"[^a-zA-Z]\", \" \", essay_v)\n",
    "    words = essay_v.lower().split()\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    return (words)\n",
    "\n",
    "def essay_to_sentences(essay_v, remove_stopwords):\n",
    "    \"\"\"Sentence tokenize the essay and call essay_to_wordlist() for word tokenization.\"\"\"\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    raw_sentences = tokenizer.tokenize(essay_v.strip())\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentences.append(essay_to_wordlist(raw_sentence, remove_stopwords))\n",
    "    return sentences\n",
    "\n",
    "def makeFeatureVec(words, model, num_features):\n",
    "    \"\"\"Make Feature Vector from the words list of an Essay.\"\"\"\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    num_words = 0.\n",
    "    index2word_set = set(model.wv.index_to_key)\n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            num_words += 1\n",
    "            featureVec = np.add(featureVec,model.wv[word])        \n",
    "    featureVec = np.divide(featureVec,num_words)\n",
    "    return featureVec\n",
    "\n",
    "def getAvgFeatureVecs(essays, model, num_features):\n",
    "    \"\"\"Main function to generate the word vectors for word2vec model.\"\"\"\n",
    "    counter = 0\n",
    "    essayFeatureVecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
    "    for essay in essays:\n",
    "        essayFeatureVecs[counter] = makeFeatureVec(essay, model, num_features)\n",
    "        counter = counter + 1\n",
    "    return essayFeatureVecs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /home/harsha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/harsha/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining the model "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we define a 2-Layer LSTM Model. \n",
    "\n",
    "Note that instead of using sigmoid activation in the output layer we will use\n",
    "Relu since we are not normalising training labels."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "from keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from keras.models import Sequential\n",
    "import keras.backend as K\n",
    "\n",
    "def get_model():\n",
    "    \"\"\"Define the model.\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(300, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 300], return_sequences=True)))\n",
    "    model.add(Bidirectional(LSTM(64, recurrent_dropout=0.4)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
    "\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training Phase"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we train the model on the dataset.\n",
    "\n",
    "We will use 8-Fold Cross Validation and measure the Quadratic Weighted Kappa for each fold.\n",
    "We will then calculate Average Kappa for all the folds."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "cv = KFold(n_splits = 8, shuffle = True)\n",
    "results = []\n",
    "y_pred_list = []\n",
    "bestRes = -1\n",
    "count = 1\n",
    "for traincv, testcv in cv.split(X):\n",
    "    print(f\"\\n--------Fold {count}--------\")\n",
    "    X_test, X_train, y_test, y_train = X.iloc[testcv], X.iloc[traincv], y.iloc[testcv], y.iloc[traincv]\n",
    "    \n",
    "    train_essays = X_train['essay']\n",
    "    test_essays = X_test['essay']\n",
    "    \n",
    "    sentences = []\n",
    "    \n",
    "    #Preprocessing the essays\n",
    "    for essay in train_essays:\n",
    "            # Obtaining all sentences from the training essays.\n",
    "            sentences += essay_to_sentences(essay, remove_stopwords = True)\n",
    "            \n",
    "    # Initializing variables for word2vec model.\n",
    "    num_features = 300 \n",
    "    min_word_count = 40\n",
    "    num_workers = 4\n",
    "    context = 10\n",
    "    downsampling = 1e-3\n",
    "\n",
    "    print(\"Training Word2Vec Model...\")\n",
    "    model = Word2Vec(sentences, workers=num_workers, vector_size=num_features, min_count = min_word_count, window = context, sample = downsampling)\n",
    "\n",
    "    clean_train_essays = []\n",
    "    \n",
    "    # Generate training and testing data word vectors.\n",
    "    for essay_v in train_essays:\n",
    "        clean_train_essays.append(essay_to_wordlist(essay_v, remove_stopwords=True))\n",
    "    trainDataVecs = getAvgFeatureVecs(clean_train_essays, model, num_features)\n",
    "    \n",
    "    clean_test_essays = []\n",
    "    for essay_v in test_essays:\n",
    "        clean_test_essays.append(essay_to_wordlist( essay_v, remove_stopwords=True ))\n",
    "    testDataVecs = getAvgFeatureVecs( clean_test_essays, model, num_features )\n",
    "    \n",
    "    trainDataVecs = np.array(trainDataVecs)\n",
    "    testDataVecs = np.array(testDataVecs)\n",
    "\n",
    "    # Reshaping train and test vectors to 3 dimensions. (1 represnts one timestep)\n",
    "    trainDataVecs = np.reshape(trainDataVecs, (trainDataVecs.shape[0], 1, trainDataVecs.shape[1]))\n",
    "    testDataVecs = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))\n",
    "    \n",
    "    #Training BiLSTM model\n",
    "    lstm_model = get_model()\n",
    "    lstm_model.fit(trainDataVecs, y_train, batch_size=64, epochs=15)\n",
    "    lstm_model.summary()\n",
    "    y_pred = lstm_model.predict(testDataVecs)\n",
    "    \n",
    "    \n",
    "    # Round y_pred to the nearest integer.\n",
    "    y_pred = np.around(y_pred)\n",
    "    \n",
    "    # Evaluate the model on the evaluation metric. \"Quadratic mean averaged Kappa\"\n",
    "    result = cohen_kappa_score(y_test.values,y_pred,weights='quadratic')\n",
    "    print(f\"Kappa Score: {result}\")\n",
    "    results.append(result)\n",
    "\n",
    "    # Save the best model\n",
    "    if result > bestRes:\n",
    "        bestRes = result\n",
    "        model.wv.save_word2vec_format('word2vecmodel.bin', binary=True)\n",
    "        lstm_model.save('final_model')\n",
    "    count += 1\n",
    "        "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "--------Fold 1--------\n",
      "Training Word2Vec Model...\n",
      "Epoch 1/15\n",
      "178/178 [==============================] - 10s 26ms/step - loss: 37.5662 - mae: 3.3834\n",
      "Epoch 2/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 16.8868 - mae: 2.2727\n",
      "Epoch 3/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 10.9291 - mae: 1.8570\n",
      "Epoch 4/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 9.0685 - mae: 1.6846\n",
      "Epoch 5/15\n",
      "178/178 [==============================] - 5s 25ms/step - loss: 8.4629 - mae: 1.6180\n",
      "Epoch 6/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 7.7521 - mae: 1.5768\n",
      "Epoch 7/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 7.6293 - mae: 1.5443\n",
      "Epoch 8/15\n",
      "178/178 [==============================] - 5s 25ms/step - loss: 6.9988 - mae: 1.4813\n",
      "Epoch 9/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 7.1847 - mae: 1.4941\n",
      "Epoch 10/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 6.9523 - mae: 1.4558\n",
      "Epoch 11/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 6.9836 - mae: 1.4566\n",
      "Epoch 12/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 6.7181 - mae: 1.4284\n",
      "Epoch 13/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 6.8258 - mae: 1.4266\n",
      "Epoch 14/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 6.4221 - mae: 1.4028\n",
      "Epoch 15/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 6.3310 - mae: 1.3904\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_24 (Bidirectio (None, 1, 600)            1442400   \n",
      "_________________________________________________________________\n",
      "bidirectional_25 (Bidirectio (None, 128)               340480    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,783,009\n",
      "Trainable params: 1,783,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Kappa Score: 0.9627777697347305\n",
      "INFO:tensorflow:Assets written to: final_model/assets\n",
      "\n",
      "--------Fold 2--------\n",
      "Training Word2Vec Model...\n",
      "Epoch 1/15\n",
      "178/178 [==============================] - 11s 26ms/step - loss: 39.4825 - mae: 3.4705\n",
      "Epoch 2/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 17.3348 - mae: 2.2859\n",
      "Epoch 3/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 10.7875 - mae: 1.8380\n",
      "Epoch 4/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 9.1066 - mae: 1.6746\n",
      "Epoch 5/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 8.3931 - mae: 1.6059\n",
      "Epoch 6/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 7.9987 - mae: 1.5472\n",
      "Epoch 7/15\n",
      "178/178 [==============================] - 5s 25ms/step - loss: 7.2221 - mae: 1.5239\n",
      "Epoch 8/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 7.3746 - mae: 1.5009\n",
      "Epoch 9/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 7.2604 - mae: 1.4933\n",
      "Epoch 10/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 7.1145 - mae: 1.4660\n",
      "Epoch 11/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 6.6475 - mae: 1.4328\n",
      "Epoch 12/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 6.4792 - mae: 1.4140\n",
      "Epoch 13/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 6.8210 - mae: 1.4296\n",
      "Epoch 14/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 6.4190 - mae: 1.3944\n",
      "Epoch 15/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 6.2931 - mae: 1.3829\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_26 (Bidirectio (None, 1, 600)            1442400   \n",
      "_________________________________________________________________\n",
      "bidirectional_27 (Bidirectio (None, 128)               340480    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,783,009\n",
      "Trainable params: 1,783,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Kappa Score: 0.9616330634471401\n",
      "\n",
      "--------Fold 3--------\n",
      "Training Word2Vec Model...\n",
      "Epoch 1/15\n",
      "178/178 [==============================] - 10s 26ms/step - loss: 39.9657 - mae: 3.5076\n",
      "Epoch 2/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 17.8945 - mae: 2.3281\n",
      "Epoch 3/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 11.5937 - mae: 1.9298\n",
      "Epoch 4/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 9.4447 - mae: 1.7301\n",
      "Epoch 5/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 8.2189 - mae: 1.6098\n",
      "Epoch 6/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 7.6548 - mae: 1.5684\n",
      "Epoch 7/15\n",
      "178/178 [==============================] - 5s 25ms/step - loss: 7.7459 - mae: 1.5254\n",
      "Epoch 8/15\n",
      "178/178 [==============================] - 5s 25ms/step - loss: 7.3617 - mae: 1.5034\n",
      "Epoch 9/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 7.1009 - mae: 1.4797\n",
      "Epoch 10/15\n",
      "178/178 [==============================] - 5s 27ms/step - loss: 6.9552 - mae: 1.4591\n",
      "Epoch 11/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 6.7355 - mae: 1.4270\n",
      "Epoch 12/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 6.5299 - mae: 1.4191\n",
      "Epoch 13/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 6.8690 - mae: 1.4351\n",
      "Epoch 14/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 6.4707 - mae: 1.4072\n",
      "Epoch 15/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 6.5032 - mae: 1.4000\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_28 (Bidirectio (None, 1, 600)            1442400   \n",
      "_________________________________________________________________\n",
      "bidirectional_29 (Bidirectio (None, 128)               340480    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,783,009\n",
      "Trainable params: 1,783,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Kappa Score: 0.9649158064582236\n",
      "INFO:tensorflow:Assets written to: final_model/assets\n",
      "\n",
      "--------Fold 4--------\n",
      "Training Word2Vec Model...\n",
      "Epoch 1/15\n",
      "178/178 [==============================] - 11s 26ms/step - loss: 40.0941 - mae: 3.4508\n",
      "Epoch 2/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 18.1277 - mae: 2.3361\n",
      "Epoch 3/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 10.9892 - mae: 1.8519\n",
      "Epoch 4/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 9.0155 - mae: 1.6961\n",
      "Epoch 5/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 8.3888 - mae: 1.6303\n",
      "Epoch 6/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 7.8917 - mae: 1.5893\n",
      "Epoch 7/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 7.8060 - mae: 1.5461\n",
      "Epoch 8/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 7.7086 - mae: 1.5402\n",
      "Epoch 9/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 7.1430 - mae: 1.4912\n",
      "Epoch 10/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 7.2211 - mae: 1.4870\n",
      "Epoch 11/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 7.1773 - mae: 1.4627\n",
      "Epoch 12/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 6.9822 - mae: 1.4573\n",
      "Epoch 13/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 6.4646 - mae: 1.4134\n",
      "Epoch 14/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 6.6178 - mae: 1.4086\n",
      "Epoch 15/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 6.4057 - mae: 1.3969\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_30 (Bidirectio (None, 1, 600)            1442400   \n",
      "_________________________________________________________________\n",
      "bidirectional_31 (Bidirectio (None, 128)               340480    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,783,009\n",
      "Trainable params: 1,783,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Kappa Score: 0.968424314134244\n",
      "INFO:tensorflow:Assets written to: final_model/assets\n",
      "\n",
      "--------Fold 5--------\n",
      "Training Word2Vec Model...\n",
      "Epoch 1/15\n",
      "178/178 [==============================] - 8s 20ms/step - loss: 39.9795 - mae: 3.4213\n",
      "Epoch 2/15\n",
      "178/178 [==============================] - 4s 20ms/step - loss: 17.9648 - mae: 2.3127\n",
      "Epoch 3/15\n",
      "178/178 [==============================] - 5s 25ms/step - loss: 11.3342 - mae: 1.9135\n",
      "Epoch 4/15\n",
      "178/178 [==============================] - 5s 26ms/step - loss: 8.9014 - mae: 1.6767\n",
      "Epoch 5/15\n",
      "178/178 [==============================] - 4s 20ms/step - loss: 8.7619 - mae: 1.6349\n",
      "Epoch 6/15\n",
      "178/178 [==============================] - 4s 21ms/step - loss: 8.1770 - mae: 1.5730\n",
      "Epoch 7/15\n",
      "178/178 [==============================] - 4s 21ms/step - loss: 7.7085 - mae: 1.5455\n",
      "Epoch 8/15\n",
      "178/178 [==============================] - 4s 20ms/step - loss: 7.3231 - mae: 1.5037\n",
      "Epoch 9/15\n",
      "178/178 [==============================] - 4s 21ms/step - loss: 7.1050 - mae: 1.4749\n",
      "Epoch 10/15\n",
      "178/178 [==============================] - 4s 20ms/step - loss: 7.0104 - mae: 1.4575\n",
      "Epoch 11/15\n",
      "178/178 [==============================] - 4s 20ms/step - loss: 6.9773 - mae: 1.4564\n",
      "Epoch 12/15\n",
      "178/178 [==============================] - 4s 21ms/step - loss: 6.7132 - mae: 1.4307\n",
      "Epoch 13/15\n",
      "178/178 [==============================] - 4s 20ms/step - loss: 6.5345 - mae: 1.4124\n",
      "Epoch 14/15\n",
      "178/178 [==============================] - 4s 21ms/step - loss: 6.7169 - mae: 1.4233\n",
      "Epoch 15/15\n",
      "178/178 [==============================] - 4s 21ms/step - loss: 6.4126 - mae: 1.3929\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_32 (Bidirectio (None, 1, 600)            1442400   \n",
      "_________________________________________________________________\n",
      "bidirectional_33 (Bidirectio (None, 128)               340480    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,783,009\n",
      "Trainable params: 1,783,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Kappa Score: 0.9663560625784211\n",
      "\n",
      "--------Fold 6--------\n",
      "Training Word2Vec Model...\n",
      "Epoch 1/15\n",
      "178/178 [==============================] - 9s 20ms/step - loss: 38.6937 - mae: 3.5095\n",
      "Epoch 2/15\n",
      "178/178 [==============================] - 4s 20ms/step - loss: 16.7953 - mae: 2.2769\n",
      "Epoch 3/15\n",
      "178/178 [==============================] - 4s 20ms/step - loss: 10.7268 - mae: 1.8860\n",
      "Epoch 4/15\n",
      "178/178 [==============================] - 4s 21ms/step - loss: 8.9449 - mae: 1.6877\n",
      "Epoch 5/15\n",
      "178/178 [==============================] - 4s 21ms/step - loss: 8.0533 - mae: 1.5982\n",
      "Epoch 6/15\n",
      "178/178 [==============================] - 4s 20ms/step - loss: 7.7508 - mae: 1.5650\n",
      "Epoch 7/15\n",
      "178/178 [==============================] - 4s 20ms/step - loss: 7.8672 - mae: 1.5584\n",
      "Epoch 8/15\n",
      "178/178 [==============================] - 4s 20ms/step - loss: 7.1014 - mae: 1.4988\n",
      "Epoch 9/15\n",
      "178/178 [==============================] - 4s 20ms/step - loss: 7.5310 - mae: 1.5069\n",
      "Epoch 10/15\n",
      "178/178 [==============================] - 4s 21ms/step - loss: 7.2224 - mae: 1.4805\n",
      "Epoch 11/15\n",
      "178/178 [==============================] - 3s 20ms/step - loss: 6.7385 - mae: 1.4389\n",
      "Epoch 12/15\n",
      "178/178 [==============================] - 3s 20ms/step - loss: 7.1477 - mae: 1.4631\n",
      "Epoch 13/15\n",
      "178/178 [==============================] - 4s 20ms/step - loss: 6.6099 - mae: 1.4271\n",
      "Epoch 14/15\n",
      "178/178 [==============================] - 4s 20ms/step - loss: 6.5654 - mae: 1.3983\n",
      "Epoch 15/15\n",
      "178/178 [==============================] - 3s 20ms/step - loss: 6.2696 - mae: 1.3803\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_34 (Bidirectio (None, 1, 600)            1442400   \n",
      "_________________________________________________________________\n",
      "bidirectional_35 (Bidirectio (None, 128)               340480    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,783,009\n",
      "Trainable params: 1,783,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Kappa Score: 0.9608241090829771\n",
      "\n",
      "--------Fold 7--------\n",
      "Training Word2Vec Model...\n",
      "Epoch 1/15\n",
      "178/178 [==============================] - 8s 19ms/step - loss: 39.1799 - mae: 3.5163\n",
      "Epoch 2/15\n",
      "178/178 [==============================] - 3s 20ms/step - loss: 17.7772 - mae: 2.3281\n",
      "Epoch 3/15\n",
      "178/178 [==============================] - 3s 19ms/step - loss: 10.9915 - mae: 1.9209\n",
      "Epoch 4/15\n",
      "178/178 [==============================] - 3s 19ms/step - loss: 9.3701 - mae: 1.7899\n",
      "Epoch 5/15\n",
      "178/178 [==============================] - 3s 19ms/step - loss: 8.3711 - mae: 1.6304\n",
      "Epoch 6/15\n",
      "178/178 [==============================] - 4s 20ms/step - loss: 7.9845 - mae: 1.5741\n",
      "Epoch 7/15\n",
      "178/178 [==============================] - 3s 20ms/step - loss: 7.8393 - mae: 1.5509\n",
      "Epoch 8/15\n",
      "178/178 [==============================] - 3s 20ms/step - loss: 7.5363 - mae: 1.5109\n",
      "Epoch 9/15\n",
      "178/178 [==============================] - 4s 20ms/step - loss: 7.1742 - mae: 1.4857\n",
      "Epoch 10/15\n",
      "178/178 [==============================] - 4s 20ms/step - loss: 7.0301 - mae: 1.4562\n",
      "Epoch 11/15\n",
      "178/178 [==============================] - 3s 20ms/step - loss: 7.0776 - mae: 1.4504\n",
      "Epoch 12/15\n",
      "178/178 [==============================] - 3s 20ms/step - loss: 6.8414 - mae: 1.4382\n",
      "Epoch 13/15\n",
      "178/178 [==============================] - 3s 20ms/step - loss: 6.5136 - mae: 1.4167\n",
      "Epoch 14/15\n",
      "178/178 [==============================] - 3s 20ms/step - loss: 6.3142 - mae: 1.3944\n",
      "Epoch 15/15\n",
      "178/178 [==============================] - 4s 20ms/step - loss: 6.1494 - mae: 1.3778\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_36 (Bidirectio (None, 1, 600)            1442400   \n",
      "_________________________________________________________________\n",
      "bidirectional_37 (Bidirectio (None, 128)               340480    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,783,009\n",
      "Trainable params: 1,783,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Kappa Score: 0.962290069373062\n",
      "\n",
      "--------Fold 8--------\n",
      "Training Word2Vec Model...\n",
      "Epoch 1/15\n",
      "178/178 [==============================] - 8s 19ms/step - loss: 38.5141 - mae: 3.4056\n",
      "Epoch 2/15\n",
      "178/178 [==============================] - 3s 19ms/step - loss: 17.9678 - mae: 2.3283\n",
      "Epoch 3/15\n",
      "178/178 [==============================] - 3s 19ms/step - loss: 11.3253 - mae: 1.8936\n",
      "Epoch 4/15\n",
      "178/178 [==============================] - 4s 20ms/step - loss: 9.3789 - mae: 1.7004\n",
      "Epoch 5/15\n",
      "178/178 [==============================] - 3s 19ms/step - loss: 8.9889 - mae: 1.6561\n",
      "Epoch 6/15\n",
      "178/178 [==============================] - 3s 20ms/step - loss: 7.9992 - mae: 1.5924\n",
      "Epoch 7/15\n",
      "178/178 [==============================] - 4s 20ms/step - loss: 7.9336 - mae: 1.5660\n",
      "Epoch 8/15\n",
      "178/178 [==============================] - 4s 20ms/step - loss: 7.4326 - mae: 1.5236\n",
      "Epoch 9/15\n",
      "178/178 [==============================] - 4s 20ms/step - loss: 7.2933 - mae: 1.5013\n",
      "Epoch 10/15\n",
      "178/178 [==============================] - 3s 20ms/step - loss: 7.5235 - mae: 1.4949\n",
      "Epoch 11/15\n",
      "178/178 [==============================] - 4s 20ms/step - loss: 7.0583 - mae: 1.4636\n",
      "Epoch 12/15\n",
      "178/178 [==============================] - 4s 20ms/step - loss: 6.9507 - mae: 1.4428\n",
      "Epoch 13/15\n",
      "178/178 [==============================] - 4s 20ms/step - loss: 6.8550 - mae: 1.4423\n",
      "Epoch 14/15\n",
      "178/178 [==============================] - 4s 20ms/step - loss: 6.9171 - mae: 1.4339\n",
      "Epoch 15/15\n",
      "178/178 [==============================] - 4s 20ms/step - loss: 6.7561 - mae: 1.4169\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_38 (Bidirectio (None, 1, 600)            1442400   \n",
      "_________________________________________________________________\n",
      "bidirectional_39 (Bidirectio (None, 128)               340480    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,783,009\n",
      "Trainable params: 1,783,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Kappa Score: 0.9720226185269691\n",
      "INFO:tensorflow:Assets written to: final_model/assets\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "print(\"Average Kappa score after a 8-fold cross validation: \",np.around(np.array(results).mean(),decimals=4))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average Kappa score after a 8-fold cross validation:  0.9649\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "results"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.9627777697347305,\n",
       " 0.9616330634471401,\n",
       " 0.9649158064582236,\n",
       " 0.968424314134244,\n",
       " 0.9663560625784211,\n",
       " 0.9608241090829771,\n",
       " 0.962290069373062,\n",
       " 0.9720226185269691]"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}